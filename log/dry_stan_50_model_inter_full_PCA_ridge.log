── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──
✔ ggplot2 3.3.3     ✔ purrr   0.3.4
✔ tibble  3.1.2     ✔ dplyr   1.0.6
✔ tidyr   1.1.3     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.1
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
Loading required package: StanHeaders
rstan (Version 2.21.2, GitRev: 2e1f913d3ca3)
For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)

Attaching package: ‘rstan’

The following object is masked from ‘package:tidyr’:

    extract

This is bayesplot version 1.8.0
- Online documentation and vignettes at mc-stan.org/bayesplot
- bayesplot theme set to bayesplot::theme_default()
   * Does _not_ affect other ggplot2 plots
   * See ?bayesplot_theme_set for details on theme setting
[1] "Model  model_inter"
[1] "Model for  dry season"
[1] "Use full"
[1] "Habitat = ridge"
[1] "n_iter = 4000"
[1] "n_warm = 2000"
[1] "n_thin = 1"
[1] "n_chains = 4"
[1] "adapt_delta = 0.95"
[1] "minimum sp abund = 50"

── Column specification ────────────────────────────────────────────────────────
cols(
  qua = col_double(),
  gx = col_double(),
  gy = col_double(),
  plot = col_double(),
  tag = col_character(),
  quadrat = col_character(),
  SPcode = col_character(),
  height = col_double(),
  date = col_character(),
  census = col_character(),
  year = col_double(),
  season = col_character(),
  survive = col_double(),
  CONS = col_double(),
  CONA = col_double(),
  HETA = col_double(),
  HETS = col_double(),
  Rainfall = col_double(),
  habitat = col_character()
)


── Column specification ────────────────────────────────────────────────────────
cols(
  qua = col_double(),
  habit3 = col_character(),
  seedtrap = col_double(),
  habit5 = col_character()
)


── Column specification ────────────────────────────────────────────────────────
cols(
  SPcode = col_character(),
  LDMC = col_double(),
  WD = col_double(),
  SDMC = col_double(),
  LA = col_double(),
  SLA = col_double(),
  Chl = col_double(),
  LT = col_double(),
  C13 = col_double(),
  C = col_double(),
  N = col_double(),
  CN = col_double(),
  tlp = col_double()
)

No. of species
76
[1] "Sp-level: 1 + PC1 + PC2 + PC3"
[1] "sp number in seedling data: 66"
[1] "sp number in trait data: 66"
data{
  int<lower=0> N; // number of sample
  int<lower=1> J; // number of sp
  int<lower=1> K; // number of tree-level preditor (i.e, CONS, HETS,...)
  int<lower=1> L; // number of sp-level predictor (i.e., interecept and WP)
  int<lower=1> M; // number of seedling individuals (tag)
  int<lower=1> S; // number of site
  int<lower=1> T; // number of census
  matrix[N, K] x; // tree-level predictor
  matrix[J, L] u; // sp-level predictor
  int<lower=0,upper=1> suv[N]; // 1 or 0
  int<lower=1,upper=J> sp[N]; // integer
  int<lower=1,upper=S> plot[N]; // integer
  int<lower=1,upper=T> census[N]; // integer
  int<lower=1> tag[N]; // integer
}

parameters{
  matrix[K, J] z;
  vector[S] phi_raw;
  vector[T] xi_raw;
  vector[M] psi_raw;
  matrix[L, K] gamma;
  cholesky_factor_corr[K] L_Omega;
  vector<lower=0,upper=pi()/2>[K] tau_unif;
  vector<lower=0,upper=pi()/2>[3] sig_unif;
}

transformed parameters{
  matrix[J, K] beta;
  vector<lower=0>[K] tau;
  vector<lower=0>[3] sig;
  vector[S] phi;
  vector[T] xi;
  vector[M] psi;
  for (k in 1:K) tau[k] = 2.5 * tan(tau_unif[k]); // implies tau ~ cauchy(0, 2.5)
  for (i in 1:3) sig[i] = 2.5 * tan(sig_unif[i]); // implies sig ~ cauchy(0, 2.5)
  beta = u * gamma + (diag_pre_multiply(tau,L_Omega) * z)';
  phi = phi_raw * sig[1];
  xi = xi_raw * sig[2];
  psi = psi_raw * sig[3];
}

model {
  // Hyper-priors
  to_vector(z) ~ std_normal();
  to_vector(phi_raw) ~ std_normal();
  to_vector(xi_raw) ~ std_normal();
  to_vector(psi_raw) ~ std_normal();
  L_Omega ~ lkj_corr_cholesky(2); // uniform of L_Omega * L_Omega'
  // Priors
  to_vector(gamma) ~ normal(0, 5);
  // Likelihood
  suv ~ bernoulli_logit(rows_dot_product(beta[sp] , x) + phi[plot] + xi[census] + psi[tag]);
}

generated quantities {
  vector[N] log_lik;
  corr_matrix[K] Omega;
  Omega = multiply_lower_tri_self_transpose(L_Omega);
  for (n in 1:N) {
    log_lik[n] = bernoulli_logit_lpmf(suv[n] | dot_product(beta[sp[n],] , x[n,]) + phi[plot[n]] + xi[census[n]] + psi[tag[n]]);
  }
}
[1] "use c = 0.18 as a scaling parameter for the distance effect"
[1] "n_sp = J =66"
[1] "n_para = K = 11"
[1] "n_plot = S = 111"
[1] "n_census = T = 10"
[1] "n_tag = M = 2934"

CHECKING DATA AND PREPROCESSING FOR MODEL 'model_inter' NOW.

COMPILING MODEL 'model_inter' NOW.

STARTING SAMPLER FOR MODEL 'model_inter' NOW.

CHECKING DATA AND PREPROCESSING FOR MODEL 'model_inter' NOW.

COMPILING MODEL 'model_inter' NOW.

STARTING SAMPLER FOR MODEL 'model_inter' NOW.

CHECKING DATA AND PREPROCESSING FOR MODEL 'model_inter' NOW.

COMPILING MODEL 'model_inter' NOW.

STARTING SAMPLER FOR MODEL 'model_inter' NOW.

CHECKING DATA AND PREPROCESSING FOR MODEL 'model_inter' NOW.

CHECKING DATA AND PREPROCESSING FOR MODEL 'model_inter' NOW.

COMPILING MODEL 'model_inter' NOW.

STARTING SAMPLER FOR MODEL 'model_inter' NOW.

SAMPLING FOR MODEL 'model_inter' NOW (CHAIN 1).

COMPILING MODEL 'model_inter' NOW.

STARTING SAMPLER FOR MODEL 'model_inter' NOW.

SAMPLING FOR MODEL 'model_inter' NOW (CHAIN 2).

SAMPLING FOR MODEL 'model_inter' NOW (CHAIN 3).

SAMPLING FOR MODEL 'model_inter' NOW (CHAIN 4).
Chain 2: 
Chain 2: Gradient evaluation took 0.006334 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 63.34 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 3: 
Chain 3: Gradient evaluation took 0.006329 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 63.29 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 2: Iteration:    1 / 4000 [  0%]  (Warmup)
Chain 3: Iteration:    1 / 4000 [  0%]  (Warmup)
Chain 1: 
Chain 1: Gradient evaluation took 0.007194 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 71.94 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 4: 
Chain 4: Gradient evaluation took 0.010559 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 105.59 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 1: Iteration:    1 / 4000 [  0%]  (Warmup)
Chain 4: Iteration:    1 / 4000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 4000 [  5%]  (Warmup)
Chain 2: Iteration:  200 / 4000 [  5%]  (Warmup)
Chain 4: Iteration:  200 / 4000 [  5%]  (Warmup)
Chain 3: Iteration:  200 / 4000 [  5%]  (Warmup)
Chain 1: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 4: Iteration:  600 / 4000 [ 15%]  (Warmup)
Chain 1: Iteration:  600 / 4000 [ 15%]  (Warmup)
Chain 2: Iteration:  600 / 4000 [ 15%]  (Warmup)
Chain 3: Iteration:  600 / 4000 [ 15%]  (Warmup)
Chain 4: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 1: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 2: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 3: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 4: Iteration: 1000 / 4000 [ 25%]  (Warmup)
Chain 1: Iteration: 1000 / 4000 [ 25%]  (Warmup)
Chain 2: Iteration: 1000 / 4000 [ 25%]  (Warmup)
Chain 3: Iteration: 1000 / 4000 [ 25%]  (Warmup)
Chain 4: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 1: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 2: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 3: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 4: Iteration: 1400 / 4000 [ 35%]  (Warmup)
Chain 1: Iteration: 1400 / 4000 [ 35%]  (Warmup)
Chain 2: Iteration: 1400 / 4000 [ 35%]  (Warmup)
Chain 3: Iteration: 1400 / 4000 [ 35%]  (Warmup)
Chain 4: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 2: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 1: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 3: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 4: Iteration: 1800 / 4000 [ 45%]  (Warmup)
Chain 2: Iteration: 1800 / 4000 [ 45%]  (Warmup)
Chain 1: Iteration: 1800 / 4000 [ 45%]  (Warmup)
Chain 4: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 4: Iteration: 2001 / 4000 [ 50%]  (Sampling)
Chain 3: Iteration: 1800 / 4000 [ 45%]  (Warmup)
Chain 2: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 2: Iteration: 2001 / 4000 [ 50%]  (Sampling)
Chain 1: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 1: Iteration: 2001 / 4000 [ 50%]  (Sampling)
Chain 4: Iteration: 2200 / 4000 [ 55%]  (Sampling)
Chain 3: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 3: Iteration: 2001 / 4000 [ 50%]  (Sampling)
Chain 2: Iteration: 2200 / 4000 [ 55%]  (Sampling)
Chain 1: Iteration: 2200 / 4000 [ 55%]  (Sampling)
Chain 4: Iteration: 2400 / 4000 [ 60%]  (Sampling)
Chain 3: Iteration: 2200 / 4000 [ 55%]  (Sampling)
Chain 2: Iteration: 2400 / 4000 [ 60%]  (Sampling)
Chain 1: Iteration: 2400 / 4000 [ 60%]  (Sampling)
Chain 4: Iteration: 2600 / 4000 [ 65%]  (Sampling)
Chain 3: Iteration: 2400 / 4000 [ 60%]  (Sampling)
Chain 2: Iteration: 2600 / 4000 [ 65%]  (Sampling)
Chain 1: Iteration: 2600 / 4000 [ 65%]  (Sampling)
Chain 4: Iteration: 2800 / 4000 [ 70%]  (Sampling)
Chain 3: Iteration: 2600 / 4000 [ 65%]  (Sampling)
Chain 2: Iteration: 2800 / 4000 [ 70%]  (Sampling)
Chain 1: Iteration: 2800 / 4000 [ 70%]  (Sampling)
Chain 4: Iteration: 3000 / 4000 [ 75%]  (Sampling)
Chain 3: Iteration: 2800 / 4000 [ 70%]  (Sampling)
Chain 2: Iteration: 3000 / 4000 [ 75%]  (Sampling)
Chain 1: Iteration: 3000 / 4000 [ 75%]  (Sampling)
Chain 4: Iteration: 3200 / 4000 [ 80%]  (Sampling)
Chain 3: Iteration: 3000 / 4000 [ 75%]  (Sampling)
Chain 1: Iteration: 3200 / 4000 [ 80%]  (Sampling)
Chain 2: Iteration: 3200 / 4000 [ 80%]  (Sampling)
Chain 4: Iteration: 3400 / 4000 [ 85%]  (Sampling)
Chain 1: Iteration: 3400 / 4000 [ 85%]  (Sampling)
Chain 3: Iteration: 3200 / 4000 [ 80%]  (Sampling)
Chain 2: Iteration: 3400 / 4000 [ 85%]  (Sampling)
Chain 4: Iteration: 3600 / 4000 [ 90%]  (Sampling)
Chain 3: Iteration: 3400 / 4000 [ 85%]  (Sampling)
Chain 2: Iteration: 3600 / 4000 [ 90%]  (Sampling)
Chain 1: Iteration: 3600 / 4000 [ 90%]  (Sampling)
Chain 4: Iteration: 3800 / 4000 [ 95%]  (Sampling)
Chain 3: Iteration: 3600 / 4000 [ 90%]  (Sampling)
Chain 2: Iteration: 3800 / 4000 [ 95%]  (Sampling)
Chain 4: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 11526.7 seconds (Warm-up)
Chain 4:                7308.55 seconds (Sampling)
Chain 4:                18835.3 seconds (Total)
Chain 4: 
Chain 1: Iteration: 3800 / 4000 [ 95%]  (Sampling)
Chain 3: Iteration: 3800 / 4000 [ 95%]  (Sampling)
Chain 2: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 11857.4 seconds (Warm-up)
Chain 2:                7402.34 seconds (Sampling)
Chain 2:                19259.7 seconds (Total)
Chain 2: 
Chain 1: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 12039.1 seconds (Warm-up)
Chain 1:                7357.91 seconds (Sampling)
Chain 1:                19397 seconds (Total)
Chain 1: 
Chain 3: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 12455 seconds (Warm-up)
Chain 3:                7134.28 seconds (Sampling)
Chain 3:                19589.3 seconds (Total)
Chain 3: 
Warning messages:
1: There were 5 divergent transitions after warmup. See
http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
to find out why this is a problem and how to eliminate them. 
2: Examine the pairs() plot to diagnose sampling problems
 
3: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
http://mc-stan.org/misc/warnings.html#bulk-ess 
Inference for Stan model: model_inter.
4 chains, each with iter=4000; warmup=2000; thin=1; 
post-warmup draws per chain=2000, total post-warmup draws=8000.

                mean se_mean    sd     2.5%      25%      50%      75%    97.5%
gamma[1,1]      2.49    0.01  0.41     1.76     2.21     2.46     2.74     3.35
gamma[1,2]     -0.39    0.01  0.63    -1.71    -0.77    -0.36     0.03     0.78
gamma[1,3]     -0.86    0.00  0.28    -1.41    -1.04    -0.86    -0.67    -0.30
gamma[1,4]      0.37    0.00  0.15     0.11     0.27     0.36     0.46     0.70
gamma[1,5]      0.05    0.00  0.18    -0.30    -0.07     0.04     0.17     0.41
gamma[1,6]     -0.47    0.00  0.24    -0.93    -0.64    -0.48    -0.32     0.03
gamma[1,7]     -0.86    0.01  0.42    -1.75    -1.12    -0.85    -0.58    -0.07
gamma[1,8]     -0.07    0.00  0.15    -0.37    -0.17    -0.06     0.04     0.23
gamma[1,9]      0.05    0.00  0.11    -0.17    -0.03     0.05     0.12     0.26
gamma[1,10]     0.15    0.00  0.13    -0.11     0.06     0.15     0.23     0.41
gamma[1,11]     0.99    0.00  0.15     0.69     0.89     0.98     1.08     1.29
gamma[2,1]     -0.24    0.00  0.18    -0.60    -0.36    -0.24    -0.13     0.11
gamma[2,2]     -0.24    0.00  0.30    -0.85    -0.43    -0.24    -0.05     0.33
gamma[2,3]     -0.22    0.00  0.13    -0.48    -0.31    -0.22    -0.13     0.05
gamma[2,4]      0.08    0.00  0.07    -0.04     0.04     0.08     0.12     0.23
gamma[2,5]     -0.06    0.00  0.10    -0.25    -0.13    -0.06     0.01     0.14
gamma[2,6]     -0.22    0.00  0.11    -0.45    -0.30    -0.22    -0.14     0.00
gamma[2,7]     -0.10    0.00  0.19    -0.47    -0.22    -0.09     0.03     0.27
gamma[2,8]     -0.18    0.00  0.08    -0.35    -0.23    -0.18    -0.12    -0.02
gamma[2,9]     -0.02    0.00  0.06    -0.14    -0.05    -0.01     0.02     0.09
gamma[2,10]     0.05    0.00  0.07    -0.10     0.00     0.05     0.10     0.20
gamma[2,11]    -0.13    0.00  0.08    -0.29    -0.18    -0.13    -0.07     0.03
gamma[3,1]     -0.10    0.00  0.20    -0.50    -0.22    -0.10     0.03     0.31
gamma[3,2]     -0.38    0.01  0.38    -1.31    -0.58    -0.32    -0.13     0.22
gamma[3,3]      0.12    0.00  0.16    -0.21     0.01     0.13     0.23     0.44
gamma[3,4]      0.10    0.00  0.06    -0.01     0.06     0.10     0.14     0.23
gamma[3,5]     -0.03    0.00  0.09    -0.23    -0.09    -0.03     0.03     0.14
gamma[3,6]     -0.18    0.00  0.11    -0.40    -0.25    -0.18    -0.11     0.04
gamma[3,7]     -0.05    0.00  0.21    -0.49    -0.17    -0.04     0.08     0.35
gamma[3,8]     -0.01    0.00  0.08    -0.16    -0.06    -0.01     0.04     0.14
gamma[3,9]     -0.07    0.00  0.06    -0.19    -0.11    -0.07    -0.03     0.04
gamma[3,10]     0.03    0.00  0.07    -0.12    -0.01     0.03     0.08     0.17
gamma[3,11]    -0.07    0.00  0.10    -0.25    -0.13    -0.07     0.00     0.13
gamma[4,1]     -0.56    0.00  0.27    -1.14    -0.73    -0.55    -0.38    -0.05
gamma[4,2]     -0.13    0.01  0.47    -1.06    -0.42    -0.14     0.15     0.81
gamma[4,3]     -0.08    0.00  0.18    -0.43    -0.20    -0.08     0.04     0.28
gamma[4,4]     -0.06    0.00  0.09    -0.24    -0.11    -0.06     0.00     0.10
gamma[4,5]      0.00    0.00  0.13    -0.25    -0.08     0.00     0.09     0.26
gamma[4,6]     -0.10    0.00  0.16    -0.43    -0.20    -0.09     0.01     0.20
gamma[4,7]      0.22    0.00  0.28    -0.33     0.04     0.22     0.41     0.79
gamma[4,8]     -0.13    0.00  0.11    -0.36    -0.21    -0.13    -0.06     0.08
gamma[4,9]     -0.07    0.00  0.07    -0.23    -0.12    -0.07    -0.02     0.07
gamma[4,10]     0.13    0.00  0.11    -0.08     0.06     0.13     0.20     0.33
gamma[4,11]    -0.03    0.00  0.12    -0.26    -0.11    -0.03     0.04     0.20
sig[1]          0.44    0.00  0.08     0.31     0.39     0.44     0.49     0.60
sig[2]          0.28    0.00  0.12     0.11     0.20     0.26     0.33     0.57
sig[3]          0.65    0.01  0.22     0.15     0.52     0.67     0.80     1.04
lp__        -4606.65    4.79 90.87 -4777.62 -4671.03 -4608.01 -4546.50 -4422.20
            n_eff Rhat
gamma[1,1]   3076 1.00
gamma[1,2]   3609 1.00
gamma[1,3]   4664 1.00
gamma[1,4]   4045 1.00
gamma[1,5]   5830 1.00
gamma[1,6]   4602 1.00
gamma[1,7]   5161 1.00
gamma[1,8]   6505 1.00
gamma[1,9]   7950 1.00
gamma[1,10]  7259 1.00
gamma[1,11]  6852 1.00
gamma[2,1]   4031 1.00
gamma[2,2]   4341 1.00
gamma[2,3]   5850 1.00
gamma[2,4]   6572 1.00
gamma[2,5]   6140 1.00
gamma[2,6]   3637 1.00
gamma[2,7]   4906 1.00
gamma[2,8]   6111 1.00
gamma[2,9]   5346 1.00
gamma[2,10]  6742 1.00
gamma[2,11]  8533 1.00
gamma[3,1]   2536 1.00
gamma[3,2]   2086 1.00
gamma[3,3]   2689 1.00
gamma[3,4]   6284 1.00
gamma[3,5]   5200 1.00
gamma[3,6]   4001 1.00
gamma[3,7]   3929 1.00
gamma[3,8]   7878 1.00
gamma[3,9]  10530 1.00
gamma[3,10]  7957 1.00
gamma[3,11]  7589 1.00
gamma[4,1]   3556 1.00
gamma[4,2]   3653 1.00
gamma[4,3]   6604 1.00
gamma[4,4]   6769 1.00
gamma[4,5]   7814 1.00
gamma[4,6]   4499 1.00
gamma[4,7]   5509 1.00
gamma[4,8]   5736 1.00
gamma[4,9]   6283 1.00
gamma[4,10]  7435 1.00
gamma[4,11]  9580 1.00
sig[1]       2377 1.00
sig[2]       2420 1.00
sig[3]        302 1.02
lp__          359 1.01

Samples were drawn using NUTS(diag_e) at Tue Aug 24 14:00:37 2021.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
[1] "./rda/dry_spab_50_model_inter_full_PCA_ridge.rda"
[1] "MCMC done!!"
